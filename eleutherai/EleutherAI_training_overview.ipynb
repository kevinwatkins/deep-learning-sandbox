{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EleutherAI_training_overview.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinwatkins/deep-learning-sandbox/blob/master/eleutherai/EleutherAI_training_overview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJXwOSoeDoMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io, re, time, ast, requests, json, dateutil, IPython.display, numpy as np, matplotlib.pyplot as plt, matplotlib.image as mpimg\n",
        "openai_images = {}\n",
        "server_name = 'vm.eleuther.ai'\n",
        "omniboard_port = 8081\n",
        "repo = 'https://github.com/EleutherAI/GPTNeo/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHsT4WugDiC2",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0WUoWS1EoXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (name, url_stem, run_stem)\n",
        "tensorboards = [\n",
        "    ('gpt3-small', None, None),\n",
        "    ('gpt3-175b', None, None),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeYKfpQyF49F",
        "colab_type": "text"
      },
      "source": [
        "## Configurations\n",
        "\n",
        "Some configurations are given in a cell here; others are loaded from omniboard. Some OpenAI GPT-3 models are included for comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiinlSuoGcWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "configs = json.loads('''{\n",
        "\n",
        "\"gpt3-small\": {\n",
        "    \"train_batch_size\": 250,\n",
        "    \"train_steps\": 585938,\n",
        "    \"n_head\": 12,\n",
        "    \"n_vocab\": 50257,\n",
        "    \"n_layer\": 12,\n",
        "    \"n_embd\": 768,\n",
        "    \"n_ctx\": 2048,\n",
        "    \"mesh_shape\": \"dummy:2048\"\n",
        "},\n",
        "\n",
        "\"gpt3-175b\": {\n",
        "    \"train_batch_size\": 1600,\n",
        "    \"train_steps\": 91553,\n",
        "    \"n_head\": 96,\n",
        "    \"n_vocab\": 50257,\n",
        "    \"n_layer\": 96,\n",
        "    \"n_embd\": 12288,\n",
        "    \"n_ctx\": 2048,\n",
        "    \"mesh_shape\": \"dummy:2048\"\n",
        "}\n",
        "\n",
        "}''')\n",
        "run_datas = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSOZqGjt8w71",
        "colab_type": "text"
      },
      "source": [
        "## Omniboard connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XnQsO368ykS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "omniboard_uri = f'http://{server_name}:{omniboard_port}/sacred'\n",
        "# with open('omniboard_auth', 'r') as f:\n",
        "#     global omniboard_auth\n",
        "#     m = re.match(r'^(.+):(.+)$', f.read())\n",
        "#     omniboard_auth = (m[1], m[2])\n",
        "\n",
        "def parse_json_datetime(s):\n",
        "    return dateutil.parser.isoparse(s).timestamp()\n",
        "\n",
        "def get_omniboard_runs():\n",
        "    try:\n",
        "        resp = requests.get(f'{omniboard_uri}/api/v1/Runs', params={\n",
        "            'select': '_id,start_time,heartbeat,status,omniboard.tags'\n",
        "        })\n",
        "        resp.raise_for_status()\n",
        "\n",
        "        r_json = resp.json()\n",
        "        return {r['_id']: r for r in r_json if r['_id'] is not None}\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def get_omniboard_details(run_id):\n",
        "    try:\n",
        "        resp = requests.get(f'{omniboard_uri}/api/v1/Runs/{run_id}', params={\n",
        "            'select': 'captured_out,experiment,config,start_time'\n",
        "        })\n",
        "        resp.raise_for_status()\n",
        "\n",
        "        r_json = resp.json()\n",
        "        #print(r_json)\n",
        "        r = {}\n",
        "\n",
        "        if 'config' in r_json and 'n_head' in r_json['config']:\n",
        "            r['config'] = r_json['config']\n",
        "\n",
        "        if 'captured_out' in r_json:\n",
        "            r_out = r_json['captured_out']\n",
        "            #print(r_out[:1000])\n",
        "            match = re.search(r'^Tensorboard at port: (\\d+)$', r_out, re.MULTILINE)\n",
        "            if match:\n",
        "                r['tb_port'] = int(match[1])\n",
        "            if 'config' not in r:\n",
        "                match = re.search(r'^params = (.+)$', r_out, re.MULTILINE)\n",
        "                if match:\n",
        "                    r['config'] = ast.literal_eval(match[1])\n",
        "            match = re.search(r'^(\\d\\d\\d\\d-\\d\\d-\\d\\d) (\\d\\d:\\d\\d:\\d\\d.\\d\\d\\d\\d\\d\\d): ', r_out, re.MULTILINE)\n",
        "            if match:\n",
        "                iso_dt = f'{match[1]}T{match[2]}Z'\n",
        "                r['start_time'] = parse_json_datetime(iso_dt)\n",
        "        \n",
        "        if 'experiment' in r_json and 'repositories' in r_json['experiment']:\n",
        "            git_commits = set([\n",
        "                l['commit']\n",
        "                for l in r_json['experiment']['repositories']\n",
        "                if l['url'].casefold() == repo.casefold()\n",
        "            ])\n",
        "            if len(git_commits) > 0:\n",
        "                r['git_commit'] = git_commits.pop()\n",
        "\n",
        "        # Not reliable because existing runs get restarted under new sacred ids\n",
        "        # if 'start_time' in r_json:\n",
        "        #     r['start_time'] = parse_json_datetime(r_json['start_time'])\n",
        "\n",
        "        return r\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "def get_omniboard_run_data(run_id):\n",
        "    try:\n",
        "        resp = requests.get(f'{omniboard_uri}/api/v1/Metrics', params={\n",
        "            'query': json.dumps({'run_id': str(run_id)})\n",
        "        })\n",
        "        resp.raise_for_status()\n",
        "\n",
        "        r_json = resp.json()\n",
        "        metrics = {\n",
        "            r['name']: r\n",
        "            for r in r_json\n",
        "            if r['run_id'] == run_id\n",
        "        }\n",
        "        if 'loss' not in metrics:\n",
        "            return None\n",
        "        loss_metric = metrics['loss']\n",
        "\n",
        "        wall_time = np.array([parse_json_datetime(t) for t in loss_metric['timestamps']], dtype=float)\n",
        "        step = np.array(loss_metric['steps'], dtype=int)\n",
        "        loss = np.array(loss_metric['values'], dtype=float)\n",
        "\n",
        "        _, unique_indices = np.unique(np.array(step), return_index=True)\n",
        "\n",
        "        return list(zip(\n",
        "            wall_time[unique_indices],\n",
        "            [int(s) for s in step[unique_indices]], # urgh\n",
        "            loss[unique_indices],\n",
        "        ))\n",
        "\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def add_omniboard_run(run_id, status):\n",
        "    try:\n",
        "        details = get_omniboard_details(run_id)\n",
        "        if 'config' not in details:\n",
        "            return\n",
        "        run_config = details['config']\n",
        "        run_config['omniboard_id'] = run_id\n",
        "        run_config['omniboard_status'] = status\n",
        "        if 'git_commit' in details:\n",
        "            run_config['git_commit'] = details['git_commit']\n",
        "        if 'start_time' in details:\n",
        "            run_config['start_time'] = details['start_time']\n",
        "        model_path = run_config['model_path']\n",
        "        name = re.search(r'/([^/]+)$', model_path)[1]\n",
        "        name = f'{run_id}-{name}'\n",
        "        if name in configs:\n",
        "            return\n",
        "        configs[name] = run_config\n",
        "\n",
        "        if 'tb_port' in details and status == 'RUNNING':\n",
        "            tb_port = int(details['tb_port'])\n",
        "            tensorboards.append((name, f'http://{server_name}:{tb_port}', ''))\n",
        "        else:\n",
        "            tensorboards.append((name, None, None))\n",
        "\n",
        "        run_data = get_omniboard_run_data(run_id)\n",
        "        if run_data:\n",
        "            run_datas[name] = run_data\n",
        "    except:\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ConJDnhG89Um",
        "colab_type": "text"
      },
      "source": [
        "### Scrape the omniboard runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEAlWl0-85J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "omniboard_runs = get_omniboard_runs()\n",
        "if omniboard_runs is None:\n",
        "    raise Exception('omniboard is down')\n",
        "runs_to_include = [\n",
        "    k for (k, v) in omniboard_runs.items()\n",
        "    if v['status'] == 'RUNNING'\n",
        "    or ('omniboard' in v and 'tags' in v['omniboard'] and 'foomboard' in v['omniboard']['tags'])\n",
        "]\n",
        "runs_to_include.sort()\n",
        "for run_id in runs_to_include:\n",
        "    add_omniboard_run(run_id, omniboard_runs[run_id]['status'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgvr4MJv8TIZ",
        "colab_type": "text"
      },
      "source": [
        "## Data loading\n",
        "\n",
        "The last cell in this section will attempt to load data from all the tensorboards and create (or overwrite) local copies. The rest of the notebook operates on the local copies.\n",
	"\n",
	"FYI this section has been more or less obsoleted by the omniboard scraping, above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lddvu7MEpWK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_config_path(run):\n",
        "    return f'{run}-config.json'\n",
        "def run_data_path(run):\n",
        "    return f'{run}.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qc2i3oVleTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "request_timeout = 15\n",
        "def get_config(run):\n",
        "    if run in configs:\n",
        "        return configs[run]\n",
        "    url_stem, run_stem = tbruns[run]\n",
        "    url = f'{url_stem}/data/plugin/text/text'\n",
        "    try:\n",
        "        resp = requests.get(url, params={\n",
        "            'tag': 'run_config',\n",
        "            'run': f'{run_stem}config',\n",
        "        }, timeout=request_timeout)\n",
        "        resp.raise_for_status()\n",
        "\n",
        "        # wheeeeeeeeeee\n",
        "        json1 = resp.json()\n",
        "        text1 = json1[-1]['text']\n",
        "        text2 = re.sub('<p>(.*)</p>', '\\\\1', text1)\n",
        "        return ast.literal_eval(text2)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def get_run_data(run):\n",
        "    if run in run_datas:\n",
        "        return run_datas[run]\n",
        "    url_stem, run_stem = tbruns[run]\n",
        "    url = f'{url_stem}/data/plugin/scalars/scalars'\n",
        "    try:\n",
        "        resp = requests.get(url, params={\n",
        "            'tag': 'loss',\n",
        "            'run': f'{run_stem}.',\n",
        "            'experiment': '',\n",
        "        }, timeout=request_timeout)\n",
        "        resp.raise_for_status()\n",
        "        return resp.json()\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def update_config(run):\n",
        "    config = get_config(run)\n",
        "    if config:\n",
        "        with open(run_config_path(run), 'w') as f:\n",
        "            f.write(json.dumps(config))\n",
        "        print(f'refreshed {run} config')\n",
        "    else:\n",
        "        print(f'no luck refreshing {run} config')\n",
        "\n",
        "def update_run_data(run):\n",
        "    data = get_run_data(run)\n",
        "    if data:\n",
        "        with open(run_data_path(run), 'w') as f:\n",
        "            f.write(json.dumps(data))\n",
        "        print(f'refreshed {run}')\n",
        "    else:\n",
        "        print(f'no luck refreshing {run}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0msYuBwfogn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "runs = np.array([bd[0] for bd in tensorboards])\n",
        "tbruns = {bd[0]: (bd[1], bd[2]) for bd in tensorboards if bd[1]}\n",
        "for run in runs:\n",
        "    if run in tbruns and run not in configs:\n",
        "        update_config(run)\n",
        "    if run in tbruns:\n",
        "        update_run_data(run)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9xw0Ec-8gWr",
        "colab_type": "text"
      },
      "source": [
        "## Reformatting data as numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9tkyfyPo0xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_config(run):\n",
        "    if run in configs:\n",
        "        return configs[run]\n",
        "    try:\n",
        "        with open(run_config_path(run), 'r') as f:\n",
        "            return json.load(f)\n",
        "    except:\n",
        "        return None\n",
        "def load_run_data(run):\n",
        "    if run in run_datas:\n",
        "        return run_datas[run]\n",
        "    try:\n",
        "        with open(run_data_path(run), 'r') as f:\n",
        "            return json.load(f)\n",
        "    except:\n",
        "        return []\n",
        "run_config_dict = {run: load_config(run) for run in runs}\n",
        "runs = [run for run in runs if run_config_dict[run] is not None]\n",
        "run_data_list = [load_run_data(run) for run in runs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPBnCyhtjqKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cfarray(key, default_value=np.nan):\n",
        "    return np.array([run_config_dict[run].get(key, default_value) for run in runs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY5mLbszkCT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch_size = cfarray('train_batch_size')\n",
        "n_head = cfarray('n_head')\n",
        "n_vocab = cfarray('n_vocab')\n",
        "n_layer = cfarray('n_layer')\n",
        "n_embd = cfarray('n_embd')\n",
        "n_ctx = cfarray('n_ctx')\n",
        "mesh_shape = cfarray('mesh_shape')\n",
        "train_steps = cfarray('train_steps')\n",
        "omniboard_id = cfarray('omniboard_id')\n",
        "start_time = cfarray('start_time')\n",
        "git_commit = cfarray('git_commit', '')\n",
        "tpu_name = cfarray('tpu_name', '')\n",
        "omniboard_status = cfarray('omniboard_status', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meHorq8gtlSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_rows = np.array([len(d) for d in run_data_list])\n",
        "run_data = np.full([len(runs), max(1, max(n_rows)), 3], np.nan)\n",
        "for i in range(len(runs)):\n",
        "    data = run_data_list[i]\n",
        "    if len(data) > 0:\n",
        "        run_data[i, :len(data), :] = np.array(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw18hEigxpoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_n_cores(mesh_shape):\n",
        "    dims = mesh_shape.split(',')\n",
        "    dim_lens = [int(dim.split(':')[1]) for dim in dims]\n",
        "    return np.prod(dim_lens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cpaq_eluSbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wall_time = run_data[:, :, 0]\n",
        "step = run_data[:, :, 1]\n",
        "loss = run_data[:, :, 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEwD00Sq8sZc",
        "colab_type": "text"
      },
      "source": [
        "## Further calculated quantities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA7ZeT1YIzup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nz_rows = np.nonzero(n_rows)\n",
        "nz_last_row = n_rows[nz_rows]-1\n",
        "def last(a):\n",
        "    r = np.full(len(runs), np.nan)\n",
        "    r[nz_rows] = a[nz_rows, nz_last_row]\n",
        "    return r\n",
        "\n",
        "def get_stem(r):\n",
        "    if r in tbruns:\n",
        "        return tbruns[r][0]\n",
        "    return ''\n",
        "tb_stem = np.array([get_stem(r) for r in runs])\n",
        "time_base = wall_time[:, 0]\n",
        "step_base = step[:, 0]\n",
        "for i in range(len(runs)):\n",
        "    if not np.isnan(start_time[i]):\n",
        "        time_base[i] = start_time[i]\n",
        "        step_base[i] = 0\n",
        "wall_elapsed = last(wall_time) - time_base\n",
        "batches_elapsed = last(step) - step_base\n",
        "wall_per_batch = wall_elapsed/batches_elapsed\n",
        "tokens_per_sec = train_batch_size*n_ctx/wall_per_batch\n",
        "last_update_time = last(wall_time)\n",
        "end_step = last(step)\n",
        "end_loss = last(loss)\n",
        "fraction_done = end_step/train_steps\n",
        "flops_per_core = 52.5e12\n",
        "n_cores = np.array([get_n_cores(shape) for shape in mesh_shape], dtype=float)\n",
        "total_flops = flops_per_core*n_cores\n",
        "approx_model_params = n_layer*(n_embd.astype(float)**2)*12 + n_vocab*n_embd.astype(float)\n",
        "total_train_tokens = train_steps*n_ctx*train_batch_size.astype(float)\n",
        "total_approx_ops = approx_model_params*total_train_tokens*6\n",
        "total_pflops_days = total_approx_ops/1e15/86400\n",
        "theo_train_days = total_approx_ops/total_flops/86400\n",
        "train_tokens_elapsed = end_step*n_ctx*train_batch_size\n",
        "approx_ops_elapsed = approx_model_params*train_tokens_elapsed*6\n",
        "pflops_days_elapsed = approx_ops_elapsed/1e15/86400\n",
        "\n",
        "theo_wall_per_batch = n_ctx*train_batch_size*approx_model_params*6/total_flops\n",
        "theo_eff = theo_wall_per_batch/wall_per_batch\n",
        "wall_remaining = (total_approx_ops-approx_ops_elapsed)/total_flops/theo_eff\n",
        "est_finish_time = last_update_time + wall_remaining\n",
        "\n",
        "row_train_tokens = step*n_ctx[:, np.newaxis]*train_batch_size[:, np.newaxis].astype(float)\n",
        "row_approx_n_ops = approx_model_params[:, np.newaxis]*row_train_tokens*6\n",
        "row_pflops_days = row_approx_n_ops/1e15/86400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZW7LxZ5QJ2I",
        "colab_type": "text"
      },
      "source": [
        "## Model size comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqLt9-eVKeS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "md_text = []\n",
        "si_prefixes = ' kMGTPEZY'\n",
        "\n",
        "def format_val(val, format_spec):\n",
        "    if isinstance(val, float) and np.isnan(val):\n",
        "        return ''\n",
        "    if format_spec == 'utc':\n",
        "        return time.strftime('%Y-%m-%d %H:%M:%S UTC', time.gmtime(val))\n",
        "    si_index = 0\n",
        "    if len(format_spec) > 0 and format_spec[-1] == 'S':\n",
        "        format_spec = format_spec[:-1] + 'f'\n",
        "        while val/(1e3**si_index) >= 1e3 and si_index < len(si_prefixes) - 1:\n",
        "            si_index += 1\n",
        "        s = format(val/(1e3**si_index), format_spec)\n",
        "        if si_index > 0:\n",
        "            s = s + ' ' + si_prefixes[si_index]\n",
        "        return s\n",
        "    return format(val, format_spec)\n",
        "\n",
        "def add_row(name, values=[], format_spec=''):\n",
        "    global md_text\n",
        "    md_text.append(f'| {name} ')\n",
        "    md_text += [f'| {format_val(v, format_spec)} ' for v in values]\n",
        "    md_text.append('|\\n')\n",
        "\n",
        "blanks = ['' for r in runs]\n",
        "add_row(' ', runs)\n",
        "add_row('----', ['----:' for r in runs])\n",
        "add_row('**Model shape**', blanks)\n",
        "add_row('git_commit', [f'[{c[:7]}]({repo}/tree/{c})' if len(c) else '' for c in git_commit])\n",
        "add_row('n_head', n_head)\n",
        "add_row('n_vocab', n_vocab)\n",
        "add_row('n_layer', n_layer)\n",
        "add_row('n_embd', n_embd)\n",
        "add_row('n_ctx', n_ctx)\n",
        "add_row('approx_model_params', approx_model_params, '.2S')\n",
        "add_row('**Training size**', blanks)\n",
        "add_row('train_batch_size', train_batch_size)\n",
        "add_row('train_steps', train_steps)\n",
        "add_row('total_train_tokens', total_train_tokens, '.2S')\n",
        "add_row('total_approx_ops', total_approx_ops, '.2e')\n",
        "add_row('total_pflops_days', total_pflops_days, '.2f')\n",
        "add_row('**TPU**', blanks)\n",
        "add_row('tpu_name', tpu_name)\n",
        "add_row('n_cores', n_cores, '.0f')\n",
        "add_row('total_flops', total_flops, '.2S')\n",
        "add_row('theo_train_days', theo_train_days, '.2f')\n",
        "add_row('**Training progress**', blanks)\n",
        "add_row('tb_url', [f'[{s[7:]}]({s})' if len(s) else '' for s in tb_stem])\n",
        "add_row('sacred_id', [f'[{int(id)}]({omniboard_uri}?runId={int(id)})'\n",
        "    if not np.isnan(id) else '' for id in omniboard_id])\n",
        "add_row('status', omniboard_status)\n",
        "add_row('start_time', start_time, 'utc')\n",
        "add_row('n_updates', n_rows)\n",
        "add_row('last_update_time', last_update_time, 'utc')\n",
        "add_row('wall_time_secs', wall_elapsed, '.1f')\n",
        "add_row('latest_batch', end_step, '.0f')\n",
        "add_row('latest_loss', end_loss, '.2f')\n",
        "add_row('fraction_done', fraction_done, '.4f')\n",
        "add_row('train_tokens_elapsed', train_tokens_elapsed, '.2S')\n",
        "add_row('approx_ops_elapsed', approx_ops_elapsed, '.2e')\n",
        "add_row('pflops_days_elapsed', pflops_days_elapsed, '.2f')\n",
        "add_row('secs_per_batch', wall_per_batch, '.2f')\n",
        "add_row('tokens_per_sec', tokens_per_sec, '.0f')\n",
        "add_row('theo_eff', theo_eff, '.3f')\n",
        "add_row('wall_remaining_secs', wall_remaining, '.0f')\n",
        "add_row('est_finish_time', est_finish_time, 'utc')\n",
        "\n",
        "display(\n",
        "    IPython.display.HTML('''<style>\n",
        "      table {\n",
        "        table-layout: fixed;\n",
        "        border-collapse: collapse;\n",
        "        font-size: 9pt;\n",
        "      }\n",
        "      tbody tr:nth-child(odd) {\n",
        "        background-color: #f0f0f0;\n",
        "      }\n",
        "      th {\n",
        "        width: 115px;\n",
        "      }\n",
        "      td, th {\n",
        "        padding: 2px 5px;\n",
        "      }\n",
        "    </style>'''),\n",
        "    IPython.display.Markdown(''.join(md_text))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTaOVmhK81G7",
        "colab_type": "text"
      },
      "source": [
        "## Loss vs compute plot\n",
        "\n",
        "Note: the \"compute\" axis is the theoretical pflops-days that would be consumed if the tensor operations could be run at 100% efficiency. In practice, the actual pflops-days will be greater. Also, the number of floating point operations is only approximated here.\n",
        "\n",
        "Note 2: As of this writing, EleutherAI is using its own BPE vocabulary, so in theory, losses from EleutherAI and OpenAI cannot be directly compared."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRv4f1CL2Xn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_openai_runs = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0vlP5ua418A",
        "colab_type": "text"
      },
      "source": [
        "### Implementation details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpyrlohUtFQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_colors = 'red,light blue,light green,yellow,grey,light purple,tan,black'\n",
        "plot_colors = [f'xkcd:{c}' for c in plot_colors.split(',')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBLHB3--t1th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_openai_image(name):\n",
        "    if name not in openai_images:\n",
        "        resp = requests.get(f'https://storage.googleapis.com/via-whereas/foomboard/{name}')\n",
        "        resp.raise_for_status()\n",
        "        openai_images[name] = mpimg.imread(io.BytesIO(resp.content))\n",
        "    return openai_images[name]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_bLw3DGEbK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_loss_compute_plot():\n",
        "    fig = plt.figure(figsize=(6.37, 6), dpi=100)\n",
        "\n",
        "    if show_openai_runs:\n",
        "        fig.add_subplot(label='image')\n",
        "        img = download_openai_image('LanguageModelingComputePareto.png')\n",
        "        plt.imshow(img[112:1520, 380:1912])\n",
        "        plt.axis('off')\n",
        "\n",
        "    ax = fig.add_subplot(label='runs')\n",
        "    ax.patch.set_alpha(0)\n",
        "\n",
        "    color_index = 0\n",
        "    for i in range(len(runs)):\n",
        "        (nzsteps,) = np.nonzero(step[i, :n_rows[i]])\n",
        "        if len(nzsteps) > 0:\n",
        "            plt.plot(row_pflops_days[i, nzsteps], loss[i, nzsteps],\n",
        "                     plot_colors[color_index%len(plot_colors)], label=runs[i])\n",
        "            color_index += 1\n",
        "\n",
        "    if not show_openai_runs:\n",
        "        frontier_xs = np.array([1e-6, 1e4])\n",
        "        frontier_ys = 2.57*(frontier_xs**-0.048)\n",
        "        plt.plot(frontier_xs, frontier_ys, 'k:')\n",
        "\n",
        "    plt.xlabel('Compute (pflops-days)')\n",
        "    plt.xscale('log')\n",
        "    plt.xlim(1e-6, 1e4)\n",
        "    plt.xticks(10.**np.arange(-6, 6, 2))\n",
        "\n",
        "    plt.ylabel('Loss (per token, base e)')\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1.5, 6)\n",
        "    y_ticks = [1.5] + list(range(2, 7))\n",
        "    plt.yticks(y_ticks, labels=[str(t) for t in y_ticks])\n",
        "\n",
        "    plt.legend(loc='lower left')\n",
        "    \n",
        "    plt.grid(not show_openai_runs)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHwR73As5N33",
        "colab_type": "text"
      },
      "source": [
        "### The plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P920JQLa4hht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_loss_compute_plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re4_5CNTy1gI",
        "colab_type": "text"
      },
      "source": [
        "## Loss vs training tokens plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWLiIHTiy6Jd",
        "colab_type": "text"
      },
      "source": [
        "### Implementation details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad_cfpptc7kZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_loss_tokens_plot():\n",
        "    fig = plt.figure(figsize=(7.5, 5.69), dpi=100)\n",
        "\n",
        "    if show_openai_runs:\n",
        "        fig.add_subplot(label='image')\n",
        "        img = download_openai_image('training_curves.png')\n",
        "        plt.xlim(-3, 1538-214)\n",
        "        plt.ylim(845-58, -198)\n",
        "        plt.imshow(img[58:845, 214:1538])\n",
        "        plt.axis('off')\n",
        "\n",
        "    ax = fig.add_subplot(label='runs')\n",
        "    ax.patch.set_alpha(0)\n",
        "\n",
        "    color_index = 0\n",
        "    for i in range(len(runs)):\n",
        "        (nzsteps,) = np.nonzero(step[i, :n_rows[i]])\n",
        "        if len(nzsteps) > 0:\n",
        "            plt.plot(row_train_tokens[i, nzsteps]*1e-9, loss[i, nzsteps],\n",
        "                     plot_colors[color_index%len(plot_colors)], label=runs[i])\n",
        "            color_index += 1\n",
        "\n",
        "    plt.xlabel('Training tokens (billions)')\n",
        "    plt.xlim(-10, 300)\n",
        "    plt.xticks(np.arange(0, 301, 50))\n",
        "\n",
        "    plt.ylabel('Loss (per token, base e)')\n",
        "    plt.ylim(1.5, 4.0)\n",
        "    plt.yticks(np.arange(1.5, 4.001, 0.25))\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    \n",
        "    plt.grid(not show_openai_runs)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czq6lIlAy-ll",
        "colab_type": "text"
      },
      "source": [
        "### The plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkPlx9xxiaPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_loss_tokens_plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
