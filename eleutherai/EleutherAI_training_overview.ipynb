{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EleutherAI_training_overview.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinwatkins/deep-learning-sandbox/blob/master/eleutherai/EleutherAI_training_overview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJXwOSoeDoMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io, re, time, ast, requests, json, IPython.display, numpy as np, matplotlib.pyplot as plt, matplotlib.image as mpimg\n",
        "openai_image = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHsT4WugDiC2",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0WUoWS1EoXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (name, url_stem, run_stem)\n",
        "tensorboards = [\n",
        "    ('gpt3-xl-replication-4', 'http://35.204.253.196:8071', ''),\n",
        "    ('gpt3-medium-1', 'http://34.91.164.20:8001', ''),\n",
        "    ('gpt3-medium-local', 'http://34.91.164.20:8002', ''),\n",
        "    ('gpt3-xl-replication-5', 'http://34.91.164.20:8003', ''),\n",
        "    \n",
        "    ('gpt3-small', None, None),\n",
        "    ('gpt3-175b', None, None),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeYKfpQyF49F",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters\n",
        "\n",
        "Some hyperparameters are given in a cell here; others are loaded from tensorboard. Some OpenAI GPT-3 models are included for comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiinlSuoGcWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = json.loads('''{\n",
        "\n",
        "\"run-2\": {\n",
        "    \"n_head\": 8,\n",
        "    \"n_vocab\": 32768,\n",
        "    \"embed_dropout\": 0.1,\n",
        "    \"lr\": 0.0006,\n",
        "    \"warmup_steps\": 3000,\n",
        "    \"beta1\": 0.9,\n",
        "    \"beta2\": 0.95,\n",
        "    \"epsilon\": 1e-8,\n",
        "    \"opt_name\": \"adam\",\n",
        "    \"weight_decay\": 0.1,\n",
        "    \"lr_decay\": \"linear\",\n",
        "    \"train_batch_size\": 32,\n",
        "    \"attn_dropout\": 0.1,\n",
        "    \"train_steps\": 300000,\n",
        "    \"eval_steps\": 0,\n",
        "    \"res_dropout\": 0.1,\n",
        "    \"eval_batch_size\": 32,\n",
        "    \"iterations\": 500,\n",
        "    \"n_embd\": 768,\n",
        "    \"datasets\": [[\"gs://neo-datasets/openwebtext-new/openwebtext_*.tfrecords\", \"\", 11, \"documents_random\", 1.0]],\n",
        "    \"model\": \"GPT2\",\n",
        "    \"model_path\": \"gs://neo-models/Global_long_Benchmark\",\n",
        "    \"n_ctx\": 1024,\n",
        "    \"n_layer\": 12,\n",
        "    \"scale_by_depth\": true,\n",
        "    \"scale_by_in\": true,\n",
        "    \"local\": false,\n",
        "    \"mesh_shape\": \"all:8\",\n",
        "    \"layout\": \"heads:all\",\n",
        "    \"precision\": \"float32\",\n",
        "    \"activation_function\": \"gelu\",\n",
        "    \"microbatches_per_batch\": 1\n",
        "},\n",
        "\n",
        "\"gpt3-small\": {\n",
        "    \"train_batch_size\": 250,\n",
        "    \"train_steps\": 585938,\n",
        "    \"n_head\": 12,\n",
        "    \"n_vocab\": 50257,\n",
        "    \"n_layer\": 12,\n",
        "    \"n_embd\": 768,\n",
        "    \"n_ctx\": 2048,\n",
        "    \"mesh_shape\": \"dummy:1\"\n",
        "},\n",
        "\n",
        "\"gpt3-175b\": {\n",
        "    \"train_batch_size\": 1600,\n",
        "    \"train_steps\": 91553,\n",
        "    \"n_head\": 96,\n",
        "    \"n_vocab\": 50257,\n",
        "    \"n_layer\": 96,\n",
        "    \"n_embd\": 12288,\n",
        "    \"n_ctx\": 2048,\n",
        "    \"mesh_shape\": \"dummy:1\"\n",
        "}\n",
        "\n",
        "}''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgvr4MJv8TIZ",
        "colab_type": "text"
      },
      "source": [
        "## Data loading\n",
        "\n",
        "The last cell in this section will attempt to load data from all the tensorboards and create (or overwrite) local copies. The rest of the notebook operates on the local copies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lddvu7MEpWK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_hparams_path(run):\n",
        "    return f'{run}-hparams.json'\n",
        "def run_data_path(run):\n",
        "    return f'{run}.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qc2i3oVleTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_hparams(run):\n",
        "    if run in hparams:\n",
        "        return hparams[run]\n",
        "    url_stem, run_stem = tbruns[run]\n",
        "    url = f'{url_stem}/data/plugin/text/text'\n",
        "    try:\n",
        "        resp = requests.get(url, params={\n",
        "            'tag': 'run_config',\n",
        "            'run': f'{run_stem}config',\n",
        "        })\n",
        "        resp.raise_for_status()\n",
        "\n",
        "        # wheeeeeeeeeee\n",
        "        json1 = resp.json()\n",
        "        text1 = json1[0]['text']\n",
        "        text2 = re.sub('<p>(.*)</p>', '\\\\1', text1)\n",
        "        return ast.literal_eval(text2)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def get_run_data(run):\n",
        "    url_stem, run_stem = tbruns[run]\n",
        "    url = f'{url_stem}/data/plugin/scalars/scalars'\n",
        "    try:\n",
        "        resp = requests.get(url, params={\n",
        "            'tag': 'loss',\n",
        "            'run': f'{run_stem}.',\n",
        "            'experiment': '',\n",
        "        })\n",
        "        resp.raise_for_status()\n",
        "        return resp.text\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def update_hparams(run):\n",
        "    hparams = get_hparams(run)\n",
        "    if hparams:\n",
        "        with open(run_hparams_path(run), 'w') as f:\n",
        "            f.write(json.dumps(hparams))\n",
        "        print(f'refreshed {run} hparams')\n",
        "    else:\n",
        "        print(f'no luck refreshing {run} hparams')\n",
        "\n",
        "def update_run_data(run):\n",
        "    data = get_run_data(run)\n",
        "    if data:\n",
        "        with open(run_data_path(run), 'w') as f:\n",
        "            f.write(data)\n",
        "        print(f'refreshed {run}')\n",
        "    else:\n",
        "        print(f'no luck refreshing {run}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0msYuBwfogn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "runs = np.array([bd[0] for bd in tensorboards])\n",
        "tbruns = {bd[0]: (bd[1], bd[2]) for bd in tensorboards if bd[1]}\n",
        "for run in runs:\n",
        "    if run in tbruns and run not in hparams:\n",
        "        update_hparams(run)\n",
        "    if run in tbruns:\n",
        "        update_run_data(run)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9xw0Ec-8gWr",
        "colab_type": "text"
      },
      "source": [
        "## Reformatting data as numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9tkyfyPo0xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_hparams(run):\n",
        "    if run in hparams:\n",
        "        return hparams[run]\n",
        "    try:\n",
        "        with open(run_hparams_path(run), 'r') as f:\n",
        "            return json.load(f)\n",
        "    except:\n",
        "        return None\n",
        "def load_run_data(run):\n",
        "    try:\n",
        "        with open(run_data_path(run), 'r') as f:\n",
        "            return json.load(f)\n",
        "    except:\n",
        "        return []\n",
        "run_hparams_dict = {run: load_hparams(run) for run in runs}\n",
        "runs = [run for run in runs if run_hparams_dict[run] is not None]\n",
        "run_data_list = [load_run_data(run) for run in runs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPBnCyhtjqKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hparray(key):\n",
        "    return np.array([run_hparams_dict[run][key] for run in runs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY5mLbszkCT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch_size = hparray('train_batch_size')\n",
        "n_head = hparray('n_head')\n",
        "n_vocab = hparray('n_vocab')\n",
        "n_layer = hparray('n_layer')\n",
        "n_embd = hparray('n_embd')\n",
        "n_ctx = hparray('n_ctx')\n",
        "mesh_shape = hparray('mesh_shape')\n",
        "train_steps = hparray('train_steps')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meHorq8gtlSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_rows = np.array([len(d) for d in run_data_list])\n",
        "run_data = np.full([len(runs), max(n_rows), 3], np.nan)\n",
        "for i in range(len(runs)):\n",
        "    data = run_data_list[i]\n",
        "    if len(data) > 0:\n",
        "        run_data[i, :len(data), :] = np.array(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw18hEigxpoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_n_cores(mesh_shape):\n",
        "    dims = mesh_shape.split(',')\n",
        "    dim_lens = [int(dim.split(':')[1]) for dim in dims]\n",
        "    return np.prod(dim_lens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEnvwaJ7NpFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Temporarily correcting loss for one run\n",
        "for i in range(len(runs)):\n",
        "    if runs[i] != 'gpt3-xl-replication-4':\n",
        "        continue\n",
        "    run_data[i, :, 2] *= 0.25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cpaq_eluSbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wall_time = run_data[:, :, 0]\n",
        "step = run_data[:, :, 1]\n",
        "loss = run_data[:, :, 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEwD00Sq8sZc",
        "colab_type": "text"
      },
      "source": [
        "## Further calculated quantities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA7ZeT1YIzup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nz_rows = np.nonzero(n_rows)\n",
        "nz_last_row = n_rows[nz_rows]-1\n",
        "def last(a):\n",
        "    r = np.full(len(runs), np.nan)\n",
        "    r[nz_rows] = a[nz_rows, nz_last_row]\n",
        "    return r\n",
        "\n",
        "def get_stem(r):\n",
        "    if r in tbruns:\n",
        "        return tbruns[r][0]\n",
        "    return ''\n",
        "tb_stem = np.array([get_stem(r) for r in runs])\n",
        "wall_elapsed = last(wall_time) - wall_time[:, 0]\n",
        "batches_elapsed = last(step) - step[:, 0]\n",
        "wall_per_batch = wall_elapsed/batches_elapsed\n",
        "tokens_per_sec = train_batch_size*n_ctx/wall_per_batch\n",
        "last_update_time = last(wall_time)\n",
        "end_step = last(step)\n",
        "end_loss = last(loss)\n",
        "fraction_done = end_step/train_steps\n",
        "flops_per_core = 52.5e12\n",
        "n_cores = np.array([get_n_cores(shape) for shape in mesh_shape], dtype=float)\n",
        "total_flops = flops_per_core*n_cores\n",
        "approx_model_params = n_layer*(n_embd.astype(float)**2)*12 + n_vocab*n_embd.astype(float)\n",
        "total_train_tokens = train_steps*n_ctx*train_batch_size.astype(float)\n",
        "total_approx_ops = approx_model_params*total_train_tokens*6\n",
        "total_pflops_days = total_approx_ops/1e15/86400\n",
        "train_tokens_elapsed = end_step*n_ctx*train_batch_size\n",
        "approx_ops_elapsed = approx_model_params*train_tokens_elapsed*6\n",
        "pflops_days_elapsed = approx_ops_elapsed/1e15/86400\n",
        "\n",
        "theo_wall_per_batch = n_ctx*train_batch_size*approx_model_params*6/total_flops\n",
        "theo_eff = theo_wall_per_batch/wall_per_batch\n",
        "wall_remaining = (total_approx_ops-approx_ops_elapsed)/total_flops/theo_eff\n",
        "est_finish_time = last_update_time + wall_remaining\n",
        "\n",
        "row_train_tokens = step*n_ctx[:, np.newaxis]*train_batch_size[:, np.newaxis].astype(float)\n",
        "row_approx_n_ops = approx_model_params[:, np.newaxis]*row_train_tokens*6\n",
        "row_pflops_days = row_approx_n_ops/1e15/86400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZW7LxZ5QJ2I",
        "colab_type": "text"
      },
      "source": [
        "## Model size comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqLt9-eVKeS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "md_text = []\n",
        "\n",
        "def format_val(val, format_spec):\n",
        "    if isinstance(val, float) and np.isnan(val):\n",
        "        return ''\n",
        "    elif format_spec == 'gmt':\n",
        "        return time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(val))\n",
        "    else:\n",
        "        return format(val, format_spec)\n",
        "\n",
        "def add_row(name, values=[], format_spec=''):\n",
        "    global md_text\n",
        "    md_text.append(f'| {name} ')\n",
        "    md_text += [f'| {format_val(v, format_spec)} ' for v in values]\n",
        "    md_text.append('|\\n')\n",
        "\n",
        "add_row(' ', runs)\n",
        "add_row('----', ['----:' for r in runs])\n",
        "add_row('**Model shape**')\n",
        "add_row('n_head', n_head)\n",
        "add_row('n_vocab', n_vocab)\n",
        "add_row('n_layer', n_layer)\n",
        "add_row('n_embd', n_embd)\n",
        "add_row('n_ctx', n_ctx)\n",
        "add_row('approx_model_params', approx_model_params, '.2e')\n",
        "add_row('**Training size**')\n",
        "add_row('train_batch_size', train_batch_size)\n",
        "add_row('train_steps', train_steps)\n",
        "add_row('total_train_tokens', total_train_tokens, '.2e')\n",
        "add_row('total_approx_ops', total_approx_ops, '.2e')\n",
        "add_row('total_pflops_days', total_pflops_days, '.2e')\n",
        "add_row('**TPU**')\n",
        "add_row('n_cores', n_cores, '.0f')\n",
        "add_row('total_flops', total_flops, '.2e')\n",
        "add_row('**Training progress**')\n",
        "add_row('tb_url', tb_stem)\n",
        "add_row('n_updates', n_rows)\n",
        "add_row('last_update_time', last_update_time, 'gmt')\n",
        "add_row('wall_time_secs', wall_elapsed, '.1f')\n",
        "add_row('latest_batch', end_step, '.0f')\n",
        "add_row('latest_loss', end_loss, '.2f')\n",
        "add_row('fraction_done', fraction_done, '.4f')\n",
        "add_row('train_tokens_elapsed', train_tokens_elapsed, '.2e')\n",
        "add_row('approx_ops_elapsed', approx_ops_elapsed, '.2e')\n",
        "add_row('pflops_days_elapsed', pflops_days_elapsed, '.2e')\n",
        "add_row('secs_per_batch', wall_per_batch, '.2f')\n",
        "add_row('tokens_per_sec', tokens_per_sec, '.0f')\n",
        "add_row('theo_eff', theo_eff, '.3f')\n",
        "add_row('wall_remaining_secs', wall_remaining, '.0f')\n",
        "add_row('est_finish_time', est_finish_time, 'gmt')\n",
        "\n",
        "display(\n",
        "    IPython.display.HTML('''<style>\n",
        "      table {\n",
        "        table-layout: fixed;\n",
        "        border-collapse: collapse;\n",
        "        font-size: 9pt;\n",
        "      }\n",
        "      tbody tr:nth-child(odd) {\n",
        "        background-color: #f0f0f0;\n",
        "      }\n",
        "      th {\n",
        "        width: 115px;\n",
        "      }\n",
        "      td, th {\n",
        "        padding: 2px 5px;\n",
        "        /* text-align: right; */\n",
        "      }\n",
        "      /* td:nth-child(1) {\n",
        "        font-style: italic;\n",
        "      } */\n",
        "    </style>'''),\n",
        "    IPython.display.Markdown(''.join(md_text))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTaOVmhK81G7",
        "colab_type": "text"
      },
      "source": [
        "## Loss vs compute plot\n",
        "\n",
        "Note: the \"compute\" axis is the theoretical pflops-days that would be consumed if the tensor operations could be run at 100% efficiency. In practice, the actual pflops-days will be greater. Also, the number of floating point operations is only approximated here.\n",
        "\n",
        "Note 2: As of this writing, EleutherAI is using its own BPE vocabulary, so in theory, losses from EleutherAI and OpenAI cannot be directly compared."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRv4f1CL2Xn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_openai_runs = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0vlP5ua418A",
        "colab_type": "text"
      },
      "source": [
        "### Implementation details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBLHB3--t1th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_openai_image():\n",
        "    try:\n",
        "        resp = requests.get('https://storage.googleapis.com/via-whereas/LanguageModelingComputePareto.png')\n",
        "        resp.raise_for_status()\n",
        "        return resp.content\n",
        "    except:\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_bLw3DGEbK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_loss_compute_plot():\n",
        "    global openai_image\n",
        "    fig = plt.figure(figsize=(6.37, 6), dpi=100)\n",
        "\n",
        "    if show_openai_runs:\n",
        "        fig.add_subplot(label='image')\n",
        "        if not openai_image:\n",
        "            openai_image = download_openai_image()\n",
        "        img = mpimg.imread(io.BytesIO(openai_image))\n",
        "        plt.imshow(img[112:1520, 380:1912])\n",
        "        plt.axis('off')\n",
        "\n",
        "    ax = fig.add_subplot(label='runs')\n",
        "    ax.patch.set_alpha(0)\n",
        "\n",
        "    colors = ['r', 'm', 'k']\n",
        "    for i in range(len(runs)):\n",
        "        if n_rows[i] > 0:\n",
        "            plt.plot(row_pflops_days[i, :n_rows[i]], loss[i, :n_rows[i]], colors[i%len(colors)],\n",
        "                    label=runs[i])\n",
        "\n",
        "    if not show_openai_runs:\n",
        "        frontier_xs = np.array([1e-6, 1e4])\n",
        "        frontier_ys = 2.57*(frontier_xs**-0.048)\n",
        "        plt.plot(frontier_xs, frontier_ys, 'k:')\n",
        "\n",
        "    plt.xlabel('Compute (pflops-days)')\n",
        "    plt.xscale('log')\n",
        "    plt.xlim(1e-6, 1e4)\n",
        "    plt.xticks(10.**np.arange(-6, 6, 2))\n",
        "\n",
        "    plt.ylabel('Loss')\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1.5, 6)\n",
        "    y_ticks = [1.5] + list(range(2, 7))\n",
        "    plt.yticks(y_ticks, labels=[str(t) for t in y_ticks])\n",
        "\n",
        "    plt.legend(loc='center left')\n",
        "    \n",
        "    plt.grid(not show_openai_runs)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHwR73As5N33",
        "colab_type": "text"
      },
      "source": [
        "### The plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P920JQLa4hht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_loss_compute_plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
